{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "M7P6_L3nPzP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown('# <span style=\"color:red\">'+string+'</span>'))\n",
        "\n",
        "\n",
        "if not tf.__version__ == '2.15.0':\n",
        "    printmd('<<<<<!!!!! ERROR !!!! please upgrade to TensorFlow 2.17.0, or restart your Kernel (Kernel->Restart & Clear Output)>>>>>')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "tAEswR6kUYft",
        "outputId": "5bf2f83e-ba56-4a58-b340-1abd310f5683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# <span style=\"color:red\"><<<<<!!!!! ERROR !!!! please upgrade to TensorFlow 2.17.0, or restart your Kernel (Kernel->Restart & Clear Output)>>>>></span>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "width = 28 # width of the image in pixels\n",
        "height = 28 # height of the image in pixels\n",
        "flat = width * height # number of pixels in one image\n",
        "class_output = 10 # number of possible classifications for the problem"
      ],
      "metadata": {
        "id": "nuZ5dBjUP_Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQbDJtPKQH22",
        "outputId": "2f8c42e2-9ba9-4272-83fc-51af51ac9679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]/255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqV0TKMqUjvP",
        "outputId": "613df504-7111-47b6-c7fd-1a27652875a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
              "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
              "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
              "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
              "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
              "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
              "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
              "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
              "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
              "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
              "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
              "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
              "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
              "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
              "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
              "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
              "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
              "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
              "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
              "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "Z-PBIlfnUtYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWVvnGokUwbQ",
        "outputId": "b874a212-ec09-41f3-dd12-41d152a47b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAGH_n70UzbJ",
        "outputId": "7f6fa423-9e45-4fec-ae1a-70547d05efc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXta_iabU5qC",
        "outputId": "c26d74b4-75f8-43c8-8187-ab5f28cb2420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0,\n",
              "       9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9,\n",
              "       3, 9, 8, 5, 9, 3], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"categorical labels\")\n",
        "print(y_train[0:5])\n",
        "\n",
        "# make labels one hot encoded\n",
        "# Convert y_train and y_test to integers before applying one_hot encoding\n",
        "y_train = tf.one_hot(tf.cast(y_train, dtype=tf.int32), 10) # Convert to int32\n",
        "y_test = tf.one_hot(tf.cast(y_test, dtype=tf.int32), 10) # Convert to int32\n",
        "\n",
        "print(\"one hot encoded labels\")\n",
        "print(y_train[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11GJ2i2pU9sJ",
        "outputId": "71c3a289-a9a8-4f2a-80ee-08eb5c4d6315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "categorical labels\n",
            "[5 0 4 1 9]\n",
            "one hot encoded labels\n",
            "tf.Tensor(\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]], shape=(5, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of training examples:\" , x_train.shape[0])\n",
        "print(\"number of test examples:\" , x_test.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZktDSMKVCfy",
        "outputId": "54a83c3e-fc33-49bb-dbeb-0219aa560003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of training examples: 60000\n",
            "number of test examples: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_image_train = tf.reshape(x_train, [-1,28,28,1])\n",
        "x_image_train = tf.cast(x_image_train, 'float32')\n",
        "\n",
        "x_image_test = tf.reshape(x_test, [-1,28,28,1])\n",
        "x_image_test = tf.cast(x_image_test, 'float32')\n",
        "\n",
        "#creating new dataset with reshaped inputs\n",
        "train_ds2 = tf.data.Dataset.from_tensor_slices((x_image_train, y_train)).batch(50)\n",
        "test_ds2 = tf.data.Dataset.from_tensor_slices((x_image_test, y_test)).batch(50)\n"
      ],
      "metadata": {
        "id": "PK-QqxtlQUaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_conv1 = tf.Variable(tf.random.truncated_normal([5, 5, 1, 32], stddev=0.1, seed=0))\n",
        "b_conv1 = tf.Variable(tf.constant(0.1, shape=[32])) # need 32 biases for 32 outputs\n"
      ],
      "metadata": {
        "id": "rYCx7DSeQz5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convolve1(x):\n",
        "    return(\n",
        "        tf.nn.conv2d(x, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1)\n"
      ],
      "metadata": {
        "id": "lc0gOdqyQ30z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def h_conv1(x): return(tf.nn.relu(convolve1(x)))\n",
        "def conv1(x):\n",
        "    return tf.nn.max_pool(h_conv1(x), ksize=[1, 2, 2, 1],\n",
        "                          strides=[1, 2, 2, 1], padding='SAME')\n"
      ],
      "metadata": {
        "id": "RAUnOI-zSI5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_conv2 = tf.Variable(tf.random.truncated_normal([5, 5, 32, 64], stddev=0.1, seed=1))\n",
        "b_conv2 = tf.Variable(tf.constant(0.1, shape=[64])) #need 64 biases for 64 outputs\n"
      ],
      "metadata": {
        "id": "UCAPyTR4Snzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convolve2(x):\n",
        "    return(\n",
        "    tf.nn.conv2d(conv1(x), W_conv2, strides=[1, 1, 1, 1], padding='SAME') + b_conv2)\n"
      ],
      "metadata": {
        "id": "fFfG_xMYSqmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def h_conv2(x):  return tf.nn.relu(convolve2(x))\n"
      ],
      "metadata": {
        "id": "DELIXdquSstw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv2(x):\n",
        "    return(\n",
        "    tf.nn.max_pool(h_conv2(x), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME'))\n",
        "def layer2_matrix(x): return tf.reshape(conv2(x), [-1, 7 * 7 * 64])\n"
      ],
      "metadata": {
        "id": "P1V3j7UySsnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_fc1 = tf.Variable(tf.random.truncated_normal([7 * 7 * 64, 1024], stddev=0.1, seed = 2))\n",
        "b_fc1 = tf.Variable(tf.constant(0.1, shape=[1024])) # need 1024 biases for 1024 outputs"
      ],
      "metadata": {
        "id": "UPA6TKoRS3EC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fcl(x): return tf.matmul(layer2_matrix(x), W_fc1) + b_fc1"
      ],
      "metadata": {
        "id": "e1onJ_V_S5x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def h_fc1(x): return tf.nn.relu(fcl(x))"
      ],
      "metadata": {
        "id": "UwCWPdbYS8Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def layer_drop(x): return tf.nn.dropout(h_fc1(x), keep_prob)"
      ],
      "metadata": {
        "id": "d0bORtSETD3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_fc2 = tf.Variable(tf.random.truncated_normal([1024, 10], stddev=0.1, seed = 2)) #1024 neurons\n",
        "b_fc2 = tf.Variable(tf.constant(0.1, shape=[10])) # 10 possibilities for digits [0,1,2,3,4,5,6,7,8,9]"
      ],
      "metadata": {
        "id": "IWgqXZpvTJO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fc(x): return tf.matmul(layer_drop(x), W_fc2) + b_fc2"
      ],
      "metadata": {
        "id": "Wf2fNIAbTXBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def y_CNN(x): return tf.nn.softmax(fc(x))"
      ],
      "metadata": {
        "id": "s7O3Qm4UTW3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "layer4_test =[[0.9, 0.1, 0.1],[0.9, 0.1, 0.1]]\n",
        "y_test=[[1.0, 0.0, 0.0],[1.0, 0.0, 0.0]]\n",
        "np.mean( -np.sum(y_test * np.log(layer4_test),1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXVQlYPaTxa6",
        "outputId": "046623d8-c477-4722-8bf1-92b711e5f3d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10536051565782628"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(y_label, y_pred):\n",
        "    return (-tf.reduce_sum(y_label * tf.math.log(y_pred + 1.e-10)))"
      ],
      "metadata": {
        "id": "ZfXm0h2bTziJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "id": "tElnzZfoT6z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variables = [W_conv1, b_conv1, W_conv2, b_conv2,\n",
        "             W_fc1, b_fc1, W_fc2, b_fc2, ]\n",
        "\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        current_loss = cross_entropy( y, y_CNN( x ))\n",
        "        grads = tape.gradient( current_loss , variables )\n",
        "        optimizer.apply_gradients( zip( grads , variables ) )\n",
        "        return current_loss.numpy()"
      ],
      "metadata": {
        "id": "a9qYcHb5T_Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_prediction = tf.equal(tf.argmax(y_CNN(x_image_train), axis=1), tf.argmax(y_train, axis=1))"
      ],
      "metadata": {
        "id": "lAFZpbdKUEPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of training examples:\" , x_train.shape[0])\n",
        "print(\"number of test examples:\" , x_test.shape[0])\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(50)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(50)\n",
        "train_ds\n",
        "\n",
        "# showing an example of the Flatten class and operation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "flatten = Flatten(dtype='float32')\n",
        "\n",
        "\"original data shape\"\n",
        "#print(x_train[0])\n",
        "\n",
        "\"flattened shape\"\n",
        "print(flatten(x_train)[0])"
      ],
      "metadata": {
        "id": "MNyUfAyUqx-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Weight tensor\n",
        "W = tf.Variable(tf.zeros([784, 10], tf.float32))\n",
        "# Bias tensor\n",
        "b = tf.Variable(tf.zeros([10], tf.float32))"
      ],
      "metadata": {
        "id": "WZSAHc8aq5Kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "    return tf.matmul(x,W) + b"
      ],
      "metadata": {
        "id": "W1xON3Fzq-EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a sample softmax calculation on an input vector\n",
        "vector = [10, 0.2, 8]\n",
        "softmax = tf.nn.softmax(vector)\n",
        "print(\"softmax calculation\")\n",
        "print(softmax.numpy())\n",
        "print(\"verifying normalization\")\n",
        "print(tf.reduce_sum(softmax))\n",
        "print(\"finding vector with largest value (label assignment)\")\n",
        "print(\"category\", tf.argmax(softmax).numpy())"
      ],
      "metadata": {
        "id": "cHx-Xh5trGm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def activate(x):\n",
        "    return tf.nn.softmax(forward(x))"
      ],
      "metadata": {
        "id": "OKbCkBzcrRoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(x):\n",
        "    x = flatten(x)\n",
        "    return activate(x)"
      ],
      "metadata": {
        "id": "DbtQX-J-rbEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(y_label, y_pred):\n",
        "    return (-tf.reduce_sum(y_label * tf.math.log(y_pred + 1.e-10)))\n",
        "# addition of 1e-10 to prevent errors in zero calculations\n",
        "\n",
        "# current loss function for unoptimized model\n",
        "cross_entropy(y_train, model(x_train)).numpy()"
      ],
      "metadata": {
        "id": "Yk92OJBgrekA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.25)"
      ],
      "metadata": {
        "id": "9yEq_W4RrlC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(x, y ):\n",
        "    with tf.GradientTape() as tape:\n",
        "        #compute loss function\n",
        "        current_loss = cross_entropy( y, model(x))\n",
        "        # compute gradient of loss\n",
        "        #(This is automatic! Even with specialized funcctions!)\n",
        "        grads = tape.gradient( current_loss , [W,b] )\n",
        "        # Apply SGD step to our Variables W and b\n",
        "        optimizer.apply_gradients( zip( grads , [W,b] ) )\n",
        "    return current_loss.numpy()"
      ],
      "metadata": {
        "id": "pfTe8qvrrq5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zeroing out weights in case you want to run this cell multiple times\n",
        "# Weight tensor\n",
        "W = tf.Variable(tf.zeros([784, 10],tf.float32))\n",
        "# Bias tensor\n",
        "b = tf.Variable(tf.zeros([10],tf.float32))\n",
        "\n",
        "loss_values=[]\n",
        "accuracies = []\n",
        "epochs = 100\n",
        "\n",
        "for i in range(epochs):\n",
        "    j=0\n",
        "    # each batch has 50 examples\n",
        "    for x_train_batch, y_train_batch in train_ds:\n",
        "        j+=1\n",
        "        current_loss = train_step(x_train_batch, y_train_batch)\n",
        "        if j%500==0: #reporting intermittent batch statistics\n",
        "            print(\"epoch \", str(i), \"batch\", str(j), \"loss:\", str(current_loss) )\n",
        "\n",
        "    # collecting statistics at each epoch...loss function and accuracy\n",
        "    #  loss function\n",
        "    current_loss = cross_entropy( y_train, model( x_train )).numpy()\n",
        "    loss_values.append(current_loss)\n",
        "    correct_prediction = tf.equal(tf.argmax(model(x_train), axis=1),\n",
        "                                  tf.argmax(y_train, axis=1))\n",
        "    #  accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)).numpy()\n",
        "    accuracies.append(accuracy)\n",
        "    print(\"end of epoch \", str(i), \"loss\", str(current_loss), \"accuracy\", str(accuracy) )\n",
        "correct_prediction_train = tf.equal(tf.argmax(model(x_train), axis=1),tf.argmax(y_train,axis=1))\n",
        "accuracy_train = tf.reduce_mean(tf.cast(correct_prediction_train, tf.float32)).numpy()\n",
        "\n",
        "correct_prediction_test = tf.equal(tf.argmax(model(x_test), axis=1),tf.argmax(y_test, axis=1))\n",
        "accuracy_test = tf.reduce_mean(tf.cast(correct_prediction_test, tf.float32)).numpy()\n",
        "\n",
        "print(\"training accuracy\", accuracy_train)\n",
        "print(\"test accuracy\", accuracy_test)"
      ],
      "metadata": {
        "id": "b42MjyrHr1gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "#print(loss_values)\n",
        "plt.plot(loss_values,'-ro')\n",
        "plt.title(\"loss per epoch\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")"
      ],
      "metadata": {
        "id": "G3n6xzbLsBsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(accuracies,'-ro')\n",
        "plt.title(\"accuracy per epoch\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accuracy\")"
      ],
      "metadata": {
        "id": "sasTCCeSsGOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width = 28 # width of the image in pixels\n",
        "height = 28 # height of the image in pixels\n",
        "flat = width * height # number of pixels in one image\n",
        "class_output = 10 # number of possible classifications for the problem"
      ],
      "metadata": {
        "id": "FXuNRguMsTb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_image_train = tf.reshape(x_train, [-1,28,28,1])\n",
        "x_image_train = tf.cast(x_image_train, 'float32')\n",
        "\n",
        "x_image_test = tf.reshape(x_test, [-1,28,28,1])\n",
        "x_image_test = tf.cast(x_image_test, 'float32')\n",
        "\n",
        "#creating new dataset with reshaped inputs\n",
        "train_ds2 = tf.data.Dataset.from_tensor_slices((x_image_train, y_train)).batch(50)\n",
        "test_ds2 = tf.data.Dataset.from_tensor_slices((x_image_test, y_test)).batch(50)"
      ],
      "metadata": {
        "id": "Fn-TJ9tQs3rG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_image_train = tf.slice(x_image_train,[0,0,0,0],[10000, 28, 28, 1])\n",
        "y_train = tf.slice(y_train,[0,0],[10000, 10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "qB37Mwu6zkDM",
        "outputId": "6fca1a41-d7ae-4134-8853-b46b3061851e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-63ba6bd450de>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_image_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_image_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W_conv1 = tf.Variable(tf.random.truncated_normal([5, 5, 1, 32], stddev=0.1, seed=0))\n",
        "b_conv1 = tf.Variable(tf.constant(0.1, shape=[32])) # need 32 biases for 32 outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "BalS9CuFzn3M",
        "outputId": "35bdb9e4-0fe8-4573-cc3a-11f3f310f2b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6923a764d43f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW_conv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb_conv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need 32 biases for 32 outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "W_conv1 = tf.Variable(tf.random.truncated_normal([5, 5, 1, 32], stddev=0.1, seed=0))\n",
        "b_conv1 = tf.Variable(tf.constant(0.1, shape=[32])) # need 32 biases for 32 outputs\n",
        "\n",
        "Text cell <N7MSGrZWgXWq>\n",
        "# %% [markdown]\n",
        "<img src=\"https://ibm.box.com/shared/static/vn26neef1nnv2oxn5cb3uueowcawhkgb.png\" style=\"width: 800px; height: 400px;\" alt=\"HTML5 Icon\" >\n",
        "\n",
        "</h4>Convolve with weight tensor and add biases.</h4>\n",
        "\n",
        "To create convolutional layer, we use <b>tf.nn.conv2d</b>. It computes a 2-D convolution given 4-D input and filter tensors.\n",
        "\n",
        "Inputs:\n",
        "\n",
        "-   tensor of shape [batch, in_height, in_width, in_channels]. x of shape [batch_size,28 ,28, 1]\n",
        "-   a filter / kernel tensor of shape [filter_height, filter_width, in_channels, out_channels]. W is of size [5, 5, 1, 32]\n",
        "-   stride which is  [1, 1, 1, 1]. The convolutional layer, slides the \"kernel window\" across the input tensor. As the input tensor has 4 dimensions:  [batch, height, width, channels], then the convolution operates on a 2D window on the height and width dimensions. **strides** determines how much the window shifts by in each of the dimensions. As the first and last dimensions are related to batch and channels, we set the stride to 1. But for second and third dimension, we could set other values, e.g. [1, 2, 2, 1]\n",
        "\n",
        "Process:\n",
        "\n",
        "-   Change the filter to a 2-D matrix with shape [5\\*5\\*1,32]\n",
        "-   Extracts image patches from the input tensor to form a _virtual_ tensor of shape `[batch, 28, 28, 5*5*1]`.\n",
        "-   For each batch, right-multiplies the filter matrix and the image vector.\n",
        "\n",
        "Output:\n",
        "\n",
        "-   A `Tensor` (a 2-D convolution) of size tf.Tensor 'add_7:0' shape=(?, 28, 28, 32)- Notice: the output of the first convolution layer is 32 [28x28] images. Here 32 is considered as volume/depth of the output image.\n",
        "\n",
        "\n",
        "Code cell <gqFEpMb9gXWq>\n",
        "# %% [code]\n",
        "def convolve1(x):\n",
        "    return(\n",
        "        tf.nn.conv2d(x, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1)\n",
        "\n",
        "Text cell <1O_PkrmXgXWq>\n",
        "# %% [markdown]\n",
        "<img src=\"https://ibm.box.com/shared/static/iizf4ui4b2hh9wn86pplqxu27ykpqci9.png\" style=\"width: 800px; height: 400px;\" alt=\"HTML5 Icon\" >\n",
        "\n",
        "\n",
        "Text cell <li8fq8rngXWq>\n",
        "# %% [markdown]\n",
        "<h4>Apply the ReLU activation Function</h4>\n",
        "\n",
        "\n",
        "Text cell <VYGMET7dgXWq>\n",
        "# %% [markdown]\n",
        "In this step, we just go through all outputs convolution layer, <b>convolve1</b>, and wherever a negative number occurs, we swap it out for a 0. It is called ReLU activation Function.<br> Let f(x) is a ReLU activation function $f(x) = max(0,x)$.\n",
        "\n",
        "\n",
        "Code cell <6m6pW6HDgXWq>\n",
        "# %% [code]\n",
        "def h_conv1(x): return(tf.nn.relu(convolve1(x)))\n",
        "\n",
        "Text cell <xKbplh40gXWr>\n",
        "# %% [markdown]\n",
        "<h4>Apply the max pooling</h4>\n",
        "\n",
        "\n",
        "Text cell <SnwWB-yfgXWr>\n",
        "# %% [markdown]\n",
        "<b>max pooling</b> is a form of non-linear down-sampling. It partitions the input image into a set of rectangles and, and then find the maximum value for that region.\n",
        "\n",
        "Lets use <b>tf.nn.max_pool</b> function to perform max pooling.\n",
        "<b>Kernel size:</b> 2x2 (if the window is a 2x2 matrix, it would result in one output pixel)\n",
        "<b>Strides:</b> dictates the sliding behaviour of the kernel. In this case it will move 2 pixels everytime, thus not overlapping. The input is a matrix of size 28x28x32, and the output would be a matrix of size 14x14x32.\n",
        "\n",
        "<img src=\"https://ibm.box.com/shared/static/kmaja90mn3aud9mro9cn8pbbg1h5pejy.png\" alt=\"HTML5 Icon\" style=\"width: 800px; height: 400px;\">\n",
        "\n",
        "\n",
        "Code cell <S32MqUsmgXWr>\n",
        "# %% [code]\n",
        "def conv1(x):\n",
        "    return tf.nn.max_pool(h_conv1(x), ksize=[1, 2, 2, 1],\n",
        "                          strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "Text cell <WNwOLTYTgXWr>\n",
        "# %% [markdown]\n",
        "First layer completed\n",
        "\n",
        "\n",
        "Text cell <r_K3CB5XgXWr>\n",
        "# %% [markdown]\n",
        "<h3>Convolutional Layer 2</h3>\n",
        "<h4>Weights and Biases of kernels</h4>\n",
        "\n",
        "\n",
        "Text cell <pFpT9BzfgXWr>\n",
        "# %% [markdown]\n",
        "We apply the convolution again in this layer. Lets look at the second layer kernel:\n",
        "\n",
        "-   Filter/kernel: 5x5 (25 pixels)\n",
        "-   Input channels: 32 (from the 1st Conv layer, we had 32 feature maps)\n",
        "-   64 output feature maps\n",
        "\n",
        "<b>Notice:</b> here, the input image is [14x14x32], the filter is [5x5x32], we use 64 filters of size [5x5x32], and the output of the convolutional layer would be 64 convolved image, [14x14x64].\n",
        "\n",
        "<b>Notice:</b> the convolution result of applying a filter of size [5x5x32] on image of size [14x14x32] is an image of size [14x14x1], that is, the convolution is functioning on volume.\n",
        "\n",
        "\n",
        "Code cell <OaIfgHiggXWr>\n",
        "# %% [code]\n",
        "W_conv2 = tf.Variable(tf.random.truncated_normal([5, 5, 32, 64], stddev=0.1, seed=1))\n",
        "b_conv2 = tf.Variable(tf.constant(0.1, shape=[64])) #need 64 biases for 64 outputs\n",
        "\n",
        "Text cell <gxWC0p-ggXWr>\n",
        "# %% [markdown]\n",
        "<h4>Convolve image with weight tensor and add biases.</h4>\n",
        "\n",
        "\n",
        "Code cell <ouTXIWazgXWr>\n",
        "# %% [code]\n",
        "def convolve2(x):\n",
        "    return(\n",
        "    tf.nn.conv2d(conv1(x), W_conv2, strides=[1, 1, 1, 1], padding='SAME') + b_conv2)\n",
        "\n",
        "Text cell <CWvK6KCkgXWr>\n",
        "# %% [markdown]\n",
        "<h4>Apply the ReLU activation Function</h4>\n",
        "\n",
        "\n",
        "Code cell <-aw3d0L_gXWs>\n",
        "# %% [code]\n",
        "def h_conv2(x):  return tf.nn.relu(convolve2(x))\n",
        "\n",
        "Text cell <uCLzaMdSgXWs>\n",
        "# %% [markdown]\n",
        "<h4>Apply the max pooling</h4>\n",
        "\n",
        "\n",
        "Code cell <v-rG95IfgXWs>\n",
        "# %% [code]\n",
        "def conv2(x):\n",
        "    return(\n",
        "    tf.nn.max_pool(h_conv2(x), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME'))\n",
        "\n",
        "Text cell <bSbFvUBGgXWs>\n",
        "# %% [markdown]\n",
        "Second layer completed. So, what is the output of the second layer, layer2?\n",
        "\n",
        "-   it is 64 matrix of [7x7]\n",
        "\n",
        "\n",
        "Text cell <TIFqUgSngXWs>\n",
        "# %% [markdown]\n",
        "<h3>Fully Connected Layer</h3>\n",
        "\n",
        "\n",
        "Text cell <_MoA39j2gXWs>\n",
        "# %% [markdown]\n",
        "You need a fully connected layer to use the Softmax and create the probabilities in the end. Fully connected layers take the high-level filtered images from previous layer, that is all 64 matrices, and convert them to a flat array.\n",
        "\n",
        "So, each matrix [7x7] will be converted to a matrix of [49x1], and then all of the 64 matrix will be connected, which make an array of size [3136x1]. We will connect it into another layer of size [1024x1]. So, the weight between these 2 layers will be [3136x1024]\n",
        "\n",
        "<img src=\"https://ibm.box.com/shared/static/pr9mnirmlrzm2bitf1d4jj389hyvv7ey.png\" alt=\"HTML5 Icon\" style=\"width: 800px; height: 400px;\">\n",
        "\n",
        "\n",
        "Text cell <sI1-fURKgXWs>\n",
        "# %% [markdown]\n",
        "<h4>Flattening Second Layer</h4>\n",
        "\n",
        "\n",
        "Code cell <MOqZ9lqzgXWs>\n",
        "# %% [code]\n",
        "def layer2_matrix(x): return tf.reshape(conv2(x), [-1, 7 * 7 * 64])\n",
        "\n",
        "Text cell <ULBtCUiCgXWs>\n",
        "# %% [markdown]\n",
        "<h4>Weights and Biases between layer 2 and 3</h4>\n",
        "\n",
        "\n",
        "Text cell <u_6xQkjogXWt>\n",
        "# %% [markdown]\n",
        "Composition of the feature map from the last layer (7x7) multiplied by the number of feature maps (64); 1027 outputs to Softmax layer\n",
        "\n",
        "\n",
        "Code cell <YSo29MN8gXWt>\n",
        "# %% [code]\n",
        "W_fc1 = tf.Variable(tf.random.truncated_normal([7 * 7 * 64, 1024], stddev=0.1, seed = 2))\n",
        "b_fc1 = tf.Variable(tf.constant(0.1, shape=[1024])) # need 1024 biases for 1024 outputs\n",
        "\n",
        "Text cell <w8ixW7dcgXWt>\n",
        "# %% [markdown]\n",
        "<h4>Matrix Multiplication (applying weights and biases)</h4>\n",
        "\n",
        "\n",
        "Code cell <7n7A0OAEgXWt>\n",
        "# %% [code]\n",
        "def fcl(x): return tf.matmul(layer2_matrix(x), W_fc1) + b_fc1\n",
        "\n",
        "Text cell <E8denUdrgXWt>\n",
        "# %% [markdown]\n",
        "<h4>Apply the ReLU activation Function</h4>\n",
        "\n",
        "\n",
        "Code cell <R9xr6HmpgXWt>\n",
        "# %% [code]\n",
        "def h_fc1(x): return tf.nn.relu(fcl(x))\n",
        "\n",
        "Text cell <2-KodCLRgXWt>\n",
        "# %% [markdown]\n",
        "Third layer completed\n",
        "\n",
        "\n",
        "Text cell <ZZTtPm3rgXWu>\n",
        "# %% [markdown]\n",
        "<h4>Dropout Layer, Optional phase for reducing overfitting</h4>\n",
        "\n",
        "\n",
        "Text cell <5fiZxhTpgXWu>\n",
        "# %% [markdown]\n",
        "It is a phase where the network \"forget\" some features. At each training step in a mini-batch, some units get switched off randomly so that it will not interact with the network. That is, it weights cannot be updated, nor affect the learning of the other network nodes.  This can be very useful for very large neural networks to prevent overfitting.\n",
        "\n",
        "\n",
        "Code cell <94sxZAQxgXWu>\n",
        "# %% [code]\n",
        "keep_prob=0.5\n",
        "def layer_drop(x): return tf.nn.dropout(h_fc1(x), keep_prob)\n",
        "\n",
        "Text cell <nOOmzL9HgXWu>\n",
        "# %% [markdown]\n",
        "<h4>Readout Layer (Softmax Layer)</h4>\n",
        "\n",
        "\n",
        "Text cell <XfdJfz2ogXWu>\n",
        "# %% [markdown]\n",
        "Type: Softmax, Fully Connected Layer.\n",
        "\n",
        "\n",
        "Text cell <fsHFatuEgXWv>\n",
        "# %% [markdown]\n",
        "<h4>Weights and Biases</h4>\n",
        "\n",
        "\n",
        "Text cell <Hn_IJjecgXWv>\n",
        "# %% [markdown]\n",
        "In last layer, CNN takes the high-level filtered images and translate them into votes using softmax.\n",
        "Input channels: 1024 (neurons from the 3rd Layer); 10 output features\n",
        "\n",
        "\n",
        "Code cell <TwXVFcG7gXWv>\n",
        "# %% [code]\n",
        "W_fc2 = tf.Variable(tf.random.truncated_normal([1024, 10], stddev=0.1, seed = 2)) #1024 neurons\n",
        "b_fc2 = tf.Variable(tf.constant(0.1, shape=[10])) # 10 possibilities for digits [0,1,2,3,4,5,6,7,8,9]\n",
        "\n",
        "Text cell <hLV2jgrigXWv>\n",
        "# %% [markdown]\n",
        "<h4>Matrix Multiplication (applying weights and biases)</h4>\n",
        "\n",
        "\n",
        "Code cell <UYqsUpF-gXWv>\n",
        "# %% [code]\n",
        "def fc(x): return tf.matmul(layer_drop(x), W_fc2) + b_fc2\n",
        "\n",
        "Text cell <qGfira_WgXWv>\n",
        "# %% [markdown]\n",
        "<h4>Apply the Softmax activation Function</h4>\n",
        "<b>softmax</b> allows us to interpret the outputs of <b>fcl4</b> as probabilities. So, <b>y_conv</b> is a tensor of probabilities.\n",
        "\n",
        "\n",
        "Code cell <KSKsNSzSgXWv>\n",
        "# %% [code]\n",
        "def y_CNN(x): return tf.nn.softmax(fc(x))\n",
        "\n",
        "Text cell <iv7chb4ggXWv>\n",
        "# %% [markdown]\n",
        "* * *\n",
        "\n",
        "\n",
        "Text cell <aA1ZqJpigXWv>\n",
        "# %% [markdown]\n",
        "<a id=\"ref7\"></a>\n",
        "\n",
        "<h2>Summary of the Deep Convolutional Neural Network</h2>\n",
        "\n",
        "\n",
        "Text cell <jbfw1ps_gXWw>\n",
        "# %% [markdown]\n",
        "Now is time to remember the structure of  our network\n",
        "\n",
        "\n",
        "Text cell <h6AnNWsIgXWw>\n",
        "# %% [markdown]\n",
        "#### 0) Input - MNIST dataset\n",
        "\n",
        "#### 1) Convolutional and Max-Pooling\n",
        "\n",
        "#### 2) Convolutional and Max-Pooling\n",
        "\n",
        "#### 3) Fully Connected Layer\n",
        "\n",
        "#### 4) Processing - Dropout\n",
        "\n",
        "#### 5) Readout layer - Fully Connected\n",
        "\n",
        "#### 6) Outputs - Classified digits\n",
        "\n",
        "\n",
        "Text cell <ssjPiIXMgXWw>\n",
        "# %% [markdown]\n",
        "* * *\n",
        "\n",
        "\n",
        "Text cell <WemsVCR6gXWw>\n",
        "# %% [markdown]\n",
        "<a id=\"ref8\"></a>\n",
        "\n",
        "<h2>Define functions and train the model</h2>\n",
        "\n",
        "\n",
        "Text cell <plztfol9gXWw>\n",
        "# %% [markdown]\n",
        "<h4>Define the loss function</h4>\n",
        "\n",
        "We need to compare our output, layer4 tensor, with ground truth for all mini_batch. we can use <b>cross entropy>/b> to see how bad our CNN is working - to measure the error at a softmax layer.\n",
        "\n",
        "The following code shows an toy sample of cross-entropy for a mini-batch of size 2 which its items have been classified. You can run it (first change the cell type to <b>code</b> in the toolbar) to see how cross entropy changes.\n",
        "\n",
        "\n",
        "Text cell <vTngITP5gXWw>\n",
        "# %% [raw]\n",
        "import numpy as np\n",
        "layer4_test =[[0.9, 0.1, 0.1],[0.9, 0.1, 0.1]]\n",
        "y_test=[[1.0, 0.0, 0.0],[1.0, 0.0, 0.0]]\n",
        "np.mean( -np.sum(y_test * np.log(layer4_test),1))\n",
        "\n",
        "Text cell <muWAhNOFgXWw>\n",
        "# %% [markdown]\n",
        "<b>reduce_sum</b> computes the sum of elements of <b>(y_ * tf.log(layer4)</b> across second dimension of the tensor, and <b>reduce_mean</b> computes the mean of all elements in the tensor..\n",
        "\n",
        "$$ CrossEntropy = \\sum{y_{Label}\\cdot \\log(y_{Prediction})}$$\n",
        "\n",
        "\n",
        "Code cell <3TNInHf8gXWw>\n",
        "# %% [code]\n",
        "def cross_entropy(y_label, y_pred):\n",
        "    return (-tf.reduce_sum(y_label * tf.math.log(y_pred + 1.e-10)))\n",
        "\n",
        "Text cell <y9VfJgNRgXWw>\n",
        "# %% [markdown]\n",
        "<h4>Define the optimizer</h4>\n",
        "\n",
        "It is obvious that we want minimize the error of our network which is calculated by cross_entropy metric. To solve the problem, we have to compute gradients for the loss (which is minimizing the cross-entropy) and apply gradients to variables. It will be done by an optimizer: GradientDescent or Adagrad.\n",
        "\n",
        "\n",
        "Code cell <T6GICWzbgXWw>\n",
        "# %% [code]\n",
        "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "Text cell <N2FtrishgXWw>\n",
        "# %% [markdown]\n",
        "Following the convention of our first example, we will use `GradientTape` to define a model.\n",
        "\n",
        "\n",
        "Code cell <_LpdCGQ6gXWw>\n",
        "# %% [code]\n",
        "variables = [W_conv1, b_conv1, W_conv2, b_conv2,\n",
        "             W_fc1, b_fc1, W_fc2, b_fc2, ]\n",
        "\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        current_loss = cross_entropy( y, y_CNN( x ))\n",
        "        grads = tape.gradient( current_loss , variables )\n",
        "        optimizer.apply_gradients( zip( grads , variables ) )\n",
        "        return current_loss.numpy()\n",
        "\n",
        "\n",
        "Code cell <mGOX6_1xgXWx>\n",
        "# %% [code]\n",
        "\"\"\"results = []\n",
        "increment = 1000\n",
        "for start in range(0,60000,increment):\n",
        "    s = tf.slice(x_image_train,[start,0,0,0],[start+increment-1, 28, 28, 1])\n",
        "    t = y_CNN(s)\n",
        "    #results.append(t)\n",
        "\"\"\"\n",
        "Execution output\n",
        "0KB\n",
        "\ttext/plain\n",
        "\t\t'results = []\\nincrement = 1000\\nfor start in range(0,60000,increment):\\n    s = tf.slice(x_image_train,[start,0,0,0],[start+increment-1, 28, 28, 1])\\n    t = y_CNN(s)\\n    #results.append(t)\\n'\n",
        "\n",
        "Text cell <0XmkgzTogXWx>\n",
        "# %% [markdown]\n",
        "<h4>Define prediction</h4>\n",
        "Do you want to know how many of the cases in a mini-batch has been classified correctly? lets count them.\n",
        "\n",
        "\n",
        "Code cell <7JK6wYWBgXWx>\n",
        "# %% [code]\n",
        "correct_prediction = tf.equal(tf.argmax(y_CNN(x_image_train), axis=1), tf.argmax(y_train, axis=1))\n",
        "\n",
        "Text cell <v1u_LpFtgXWx>\n",
        "# %% [markdown]\n",
        "<h4>Define accuracy</h4>\n",
        "It makes more sense to report accuracy using average of correct cases.\n",
        "\n",
        "\n",
        "Code cell <C9R0d4V3gXWx>\n",
        "# %% [code]\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float32'))\n",
        "\n",
        "Text cell <fW0-o9TugXWx>\n",
        "# %% [markdown]\n",
        "<h4>Run session, train</h4>\n",
        "\n",
        "\n",
        "Text cell <o0qG86hUgXWx>\n",
        "# %% [markdown]\n",
        "<i>If you want a fast result (<b>it might take sometime to train it</b>)</i>\n",
        "\n",
        "\n",
        "Code cell <r0mE9RrfgXWx>\n",
        "# %% [code]\n",
        "loss_values=[]\n",
        "accuracies = []\n",
        "epochs = 1\n",
        "\n",
        "for i in range(epochs):\n",
        "    j=0\n",
        "    # each batch has 50 examples\n",
        "    for x_train_batch, y_train_batch in train_ds2:\n",
        "        j+=1\n",
        "        current_loss = train_step(x_train_batch, y_train_batch)\n",
        "        if j%50==0: #reporting intermittent batch statistics\n",
        "            correct_prediction = tf.equal(tf.argmax(y_CNN(x_train_batch), axis=1),\n",
        "                                  tf.argmax(y_train_batch, axis=1))\n",
        "            #  accuracy\n",
        "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)).numpy()\n",
        "            print(\"epoch \", str(i), \"batch\", str(j), \"loss:\", str(current_loss),\n",
        "                     \"accuracy\", str(accuracy))\n",
        "\n",
        "    current_loss = cross_entropy( y_train, y_CNN( x_image_train )).numpy()\n",
        "    loss_values.append(current_loss)\n",
        "    correct_prediction = tf.equal(tf.argmax(y_CNN(x_image_train), axis=1),\n",
        "                                  tf.argmax(y_train, axis=1))\n",
        "    #  accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)).numpy()\n",
        "    accuracies.append(accuracy)\n",
        "    print(\"end of epoch \", str(i), \"loss\", str(current_loss), \"accuracy\", str(accuracy) )\n",
        "Execution output\n",
        "1KB\n",
        "\tStream\n",
        "\t\tepoch  0 batch 50 loss: 133.42038 accuracy 0.46\n",
        "\t\tepoch  0 batch 100 loss: 61.91632 accuracy 0.72\n",
        "\t\tepoch  0 batch 150 loss: 47.366875 accuracy 0.84\n",
        "\t\tepoch  0 batch 200 loss: 20.221106 accuracy 0.88\n",
        "\t\tepoch  0 batch 250 loss: 32.49733 accuracy 0.82\n",
        "\t\tepoch  0 batch 300 loss: 18.42619 accuracy 0.88\n",
        "\t\tepoch  0 batch 350 loss: 28.903078 accuracy 0.82\n",
        "\t\tepoch  0 batch 400 loss: 9.930068 accuracy 0.9\n",
        "\t\tepoch  0 batch 450 loss: 31.451693 accuracy 0.84\n",
        "\t\tepoch  0 batch 500 loss: 18.593328 accuracy 0.92\n",
        "\t\tepoch  0 batch 550 loss: 15.98876 accuracy 0.9\n",
        "\t\tepoch  0 batch 600 loss: 21.600845 accuracy 0.9\n",
        "\t\tepoch  0 batch 650 loss: 19.24796 accuracy 0.86\n",
        "\t\tepoch  0 batch 700 loss: 9.7369175 accuracy 0.92\n",
        "\t\tepoch  0 batch 750 loss: 33.084084 accuracy 0.92\n",
        "\t\tepoch  0 batch 800 loss: 11.409676 accuracy 0.88\n",
        "\t\tepoch  0 batch 850 loss: 14.52256 accuracy 0.9\n",
        "\t\tepoch  0 batch 900 loss: 10.0998955 accuracy 0.9\n",
        "\t\tepoch  0 batch 950 loss: 15.64908 accuracy 0.9\n",
        "\t\tepoch  0 batch 1000 loss: 12.104089 accuracy 0.88\n",
        "\t\tepoch  0 batch 1050 loss: 5.700769 accuracy 0.98\n",
        "\t\tepoch  0 batch 1100 loss: 13.968972 accuracy 0.9\n",
        "\t\tepoch  0 batch 1150 loss: 8.938397 accuracy 0.94\n",
        "\t\tepoch  0 batch 1200 loss: 2.09421 accuracy 1.0\n",
        "\t\tend of epoch  0 loss 12035.083 accuracy 0.93768334\n",
        "\n",
        "Text cell <gt3anZNcgXWy>\n",
        "# %% [markdown]\n",
        "<i>PS. If you have problems running this notebook, please shutdown all your Jupyter runnning notebooks, clear all cells outputs and run each cell only after the completion of the previous cell.</i>\n",
        "\n",
        "\n",
        "Text cell <AC07WlGCgXWy>\n",
        "# %% [markdown]\n",
        "<hr>\n",
        "\n",
        "\n",
        "Text cell <dry8DrVRgXWy>\n",
        "# %% [markdown]\n",
        "<a id=\"ref9\"></a>\n",
        "\n",
        "<h2>Evaluate the model</h2>\n",
        "\n",
        "\n",
        "Text cell <zrx4fgWfgXWy>\n",
        "# %% [markdown]\n",
        "Print the evaluation to the user\n",
        "\n",
        "\n",
        "Code cell <m0V8WGMFgXWy>\n",
        "# %% [code]\n",
        "j=0\n",
        "acccuracies=[]\n",
        "# evaluate accuracy by batch and average...reporting every 100th batch\n",
        "for x_train_batch, y_train_batch in train_ds2:\n",
        "        j+=1\n",
        "        correct_prediction = tf.equal(tf.argmax(y_CNN(x_train_batch), axis=1),\n",
        "                                  tf.argmax(y_train_batch, axis=1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)).numpy()\n",
        "        #accuracies.append(accuracy)\n",
        "        if j%100==0:\n",
        "            print(\"batch\", str(j), \"accuracy\", str(accuracy) )\n",
        "import numpy as np\n",
        "print(\"accuracy of entire set\", str(np.mean(accuracies)))\n",
        "Execution output\n",
        "0KB\n",
        "\tStream\n",
        "\t\tbatch 100 accuracy 0.94\n",
        "\t\tbatch 200 accuracy 0.96\n",
        "\t\tbatch 300 accuracy 0.94\n",
        "\t\tbatch 400 accuracy 0.98\n",
        "\t\tbatch 500 accuracy 0.92\n",
        "\t\tbatch 600 accuracy 0.9\n",
        "\t\tbatch 700 accuracy 0.96\n",
        "\t\tbatch 800 accuracy 0.96\n",
        "\t\tbatch 900 accuracy 0.88\n",
        "\t\tbatch 1000 accuracy 0.9\n",
        "\t\tbatch 1100 accuracy 0.88\n",
        "\t\tbatch 1200 accuracy 0.96\n",
        "\t\taccuracy of entire set 0.93768334\n",
        "\n",
        "Text cell <okoqZBrXgXWy>\n",
        "# %% [markdown]\n",
        "<h3>Visualization</h3>\n",
        "\n",
        "\n",
        "Text cell <np-Qtv0DgXWy>\n",
        "# %% [markdown]\n",
        "Do you want to look at all the filters?\n",
        "\n",
        "\n",
        "Code cell <tTZpawNUgXWy>\n",
        "# %% [code]\n",
        "kernels = tf.reshape(tf.transpose(W_conv1, perm=[2, 3, 0,1]),[32, -1])\n",
        "\n",
        "Code cell <xpnYc-6mgXWz>\n",
        "# %% [code]\n",
        "!wget --output-document utils1.py https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0120EN-SkillsNetwork/labs/Week2/data/utils.py\n",
        "import utils1\n",
        "import imp\n",
        "imp.reload(utils1)\n",
        "from utils1 import tile_raster_images\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "image = Image.fromarray(tile_raster_images(kernels.numpy(), img_shape=(5, 5) ,tile_shape=(4, 8), tile_spacing=(1, 1)))\n",
        "### Plot image\n",
        "plt.rcParams['figure.figsize'] = (18.0, 18.0)\n",
        "imgplot = plt.imshow(image)\n",
        "imgplot.set_cmap('gray')\n",
        "Execution output\n",
        "1KB\n",
        "\tError\n",
        "\t\tModuleNotFoundError\n",
        "\t\t---------------------------------------------------------------------------\n",
        "\t\tModuleNotFoundError                       Traceback (most recent call last)\n",
        "\t\tCell In[52], line 2\n",
        "\t\t      1 get_ipython().system('wget --output-document utils1.py https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0120EN-SkillsNetwork/labs/Week2/data/utils.py')\n",
        "\t\t----> 2 import utils1\n",
        "\t\t      3 import imp\n",
        "\t\t      4 imp.reload(utils1)\n",
        "\n",
        "\t\tModuleNotFoundError: No module named 'utils1'\n",
        "\tStream\n",
        "\t\t'wget' is not recognized as an internal or external command,\n",
        "\t\toperable program or batch file.\n",
        "\n",
        "Text cell <6QNkDp_dgXWz>\n",
        "# %% [markdown]\n",
        "Do you want to see the output of an image passing through first convolution layer?\n",
        "\n",
        "\n",
        "Code cell <eeo-Bs9WgXWz>\n",
        "# %% [code]\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (5.0, 5.0)\n",
        "sampleimage = [x_image_train[0]]\n",
        "plt.imshow(np.reshape(sampleimage,[28,28]), cmap=\"gray\")\n"
      ],
      "metadata": {
        "id": "Gy8FbrjQYJUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess data\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#model summary\n",
        "print(model.summary)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_split=0.2, verbose=2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}\")\n",
        "\n",
        "# Save the model\n",
        "model.save('mnist_cnn_model.h5')\n"
      ],
      "metadata": {
        "id": "PjcnT8FSZ-e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "u_gLdXIoaAi2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}